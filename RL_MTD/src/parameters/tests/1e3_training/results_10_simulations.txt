*********************************************************************
Starting Simulation Types: A2C, PPO, Defender2000, Random, Static
Simulations per Type:      10
Steps per Simulation:      5000
---------------------------------------------------------------------
Only Nodes:                False
Only Detection Systems:    False
Nodes Pause:               1
Detection Systems Pause:   1
*********************************************************************
Simulation Type:          A2C
Learning Time:            unknown
---------------------------------------------------------------------
Avg steps:                305.4
Avg reward/step:          35.638
Avg null action ratio:    [0.099, 0.231]
Avg invalid actions:      [0.0, 0.0]

Min steps:                16
Max steps:                703

Defender wins:            0
Attacker wins:            10

Steps each sim:           [256, 97, 426, 620, 173, 329, 703, 16, 208, 226]
Reward each sim:          [9613, 3579, 16236, 22196, 6311, 10413, 25768, 221, 7378, 7122]
*********************************************************************
Simulation Type:          PPO
Learning Time:            unknown
---------------------------------------------------------------------
Avg steps:                120.1
Avg reward/step:          31.303
Avg null action ratio:    [0.118, 0.263]
Avg invalid actions:      [0.0, 0.0]

Min steps:                24
Max steps:                261

Defender wins:            0
Attacker wins:            10

Steps each sim:           [62, 41, 146, 184, 261, 160, 164, 24, 35, 124]
Reward each sim:          [1635, 499, 4241, 6370, 9097, 4957, 5249, 351, 901, 4295]
*********************************************************************
Simulation Type:          Defender2000
Learning Time:            0 sec
---------------------------------------------------------------------
Avg steps:                266.3
Avg reward/step:          35.363
Avg null action ratio:    [0.098, 0.267]
Avg invalid actions:      [0.0, 0.0]

Min steps:                26
Max steps:                743

Defender wins:            0
Attacker wins:            10

Steps each sim:           [95, 135, 554, 239, 328, 26, 240, 743, 105, 198]
Reward each sim:          [3131, 4655, 19116, 8973, 11943, 614, 8858, 26804, 3475, 6604]
*********************************************************************
Simulation Type:          Random
Learning Time:            0 sec
---------------------------------------------------------------------
Avg steps:                127.4
Avg reward/step:          28.582
Avg null action ratio:    [0.125, 0.352]
Avg invalid actions:      [0.0, 0.0]

Min steps:                29
Max steps:                298

Defender wins:            0
Attacker wins:            10

Steps each sim:           [107, 298, 34, 121, 200, 49, 128, 41, 267, 29]
Reward each sim:          [2828, 8911, 755, 3636, 6734, 1208, 3129, 1024, 7574, 614]
*********************************************************************
Simulation Type:          Static
Learning Time:            0 sec
---------------------------------------------------------------------
Avg steps:                19.0
Avg reward/step:          4.737
Avg null action ratio:    [1.0, 1.0]
Avg invalid actions:      [0.0, 0.0]

Min steps:                6
Max steps:                38

Defender wins:            0
Attacker wins:            10

Steps each sim:           [6, 24, 6, 38, 31, 23, 9, 18, 28, 7]
Reward each sim:          [-240, -310, -240, 730, 410, 230, -210, 280, 430, -180]
*********************************************************************
A2C is the most effective algorithm with 305.4 avg steps.
A2C is the most efficient algorithm with 35.638 avg reward/step.
